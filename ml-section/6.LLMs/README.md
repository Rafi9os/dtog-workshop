# Machine Learning DTOG Workshop
Workshop on how to use open LLM and build a quick solution around it.


# Introduction to Large Language Models (LLMs)

it refers to advanced AI systems designed to understand human-like text and predict next sequence of words.

Those models (DL) are trained on vast amounts of data (Mainly from internet sources) enabling them to process complex patterns, comprehend language nuances  and generate well structured human like responses.

LLMs perform various tasks such as:

* Summarization
* Translation
* Text Completion
* Conversational Interactions

LLM is a type of generative AI. Generative AI is a subset of AI that creates content based on learned patterns. This created content can be in different forms such as text, images, audio and even code. It mainly uses Deep Learning and Neural Networks to learn and analyzes from large datasets.
Two main concepts; transformers and  "self-attention" mechanisms are core components for the Generative AI to process and generate sequential data.

# Introduction to LangChain

it is an open source framework designed to facilitate the development od applications powered by LLMs.
It offers a suite of tools that simplify the construction of LLM-centric applications. it helps to manage interactions with language models, link different components and include resources such as databases and APIs.
The LangChain platform comes with a collection of APIs that developers can embed in their applications, hence allowing to leverage language processing  capabilities without having to build all the steps from scratch.

Applications like Chatbots, virtual assistants, language translations and sentiment analysis tools are all examples of LLM powered apps.
Some of the main Properties/characteristics of Langchain are:
* Tailored prompts to meet you specific requirements
* constructing chain link components for advanced usage scenarios
* wide spectrum of components that allow mixing and matching for specific needs
* Manipulating context to establish and guide context to enhance precision and user satisfaction
* integrating models such as GPT and HuggingFace Hub

