{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center; color: Blue; font-family: verdana; font-size: 40px;\">ASME DTOG: Introduction - Design of Experiments (DOE)</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Introduction](#toc1_)    \n",
    "- [Design of Experiments](#toc2_)    \n",
    "- [Simple Comparative Experiments](#toc3_)    \n",
    "    - [Statistical Concepts](#toc3_1_1_)    \n",
    "    - [Example Problem - Illustrates the Statistical Concepts](#toc3_1_2_)    \n",
    "        - [Graphical Description of Variability](#toc3_1_2_1_1_)    \n",
    "        - [histogram](#toc3_1_2_1_2_)    \n",
    "        - [ boxplot](#toc3_1_2_1_3_)    \n",
    "      - [General Observations](#toc3_1_2_2_)    \n",
    "      - [Probability Distributions](#toc3_1_2_3_)    \n",
    "        - [Probability (continuous)](#toc3_1_2_3_1_)    \n",
    "        - [Probability (discrete)](#toc3_1_2_3_2_)    \n",
    "        - [Degrees of Freedom](#toc3_1_2_3_3_)    \n",
    "        - [Normal Distributions](#toc3_1_2_3_4_)    \n",
    "        - [Central Limit Theorem (CLT)](#toc3_1_2_3_5_)    \n",
    "        - [Intuitive Understanding](#toc3_1_2_3_6_)    \n",
    "        - [Example Summary](#toc3_1_2_3_7_)    \n",
    "        - [Sampling Distributions](#toc3_1_2_3_8_)    \n",
    "        - [The sampling situation for the two-sample t-test](#toc3_1_2_3_9_)    \n",
    "    - [Simple Comparative Experiments: Concepts & Ideas](#toc3_1_3_)    \n",
    "      - [The Two-Sample t-Test](#toc3_1_3_1_)    \n",
    "      - [Recap:](#toc3_1_3_2_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Introduction](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"images/Data Driven Illustration.jpg\" width=\"540\" height=\"555\" style=\"display: block; margin-left: auto; margin-right: auto; border-radius: 8px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"images/DOE with ML.jpg\" width=\"540\" height=\"555\" style=\"display: block; margin-left: auto; margin-right: auto; border-radius: 8px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Design of Experiments](#toc0_)\n",
    "\n",
    "<span style=\"color:red\"><b>_The Design of Experiments, also known as experiment design or experimental design, is the design of any task that aims to describe and explain the variation of information under conditions that are hypothesized to reflect the variation._</b></span>\n",
    "\n",
    "The term is generally associated with experiments in which the design introduces conditions that directly affect the variation, but may also refer to the design of quasi-experiments, in which natural conditions that influence the variation are selected for observation.\n",
    "\n",
    "In its simplest form, an experiment aims at predicting the outcome by introducing a change of the preconditions, which is represented by one or more independent variables, also referred to as \"input variables\" or \"predictor variables.\" The change in one or more independent variables is generally hypothesized to result in a change in one or more dependent variables, also referred to as \"output variables\" or \"response variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main concerns in experimental design include the establishment of validity, reliability, and replicability.\n",
    "- For example, these concerns can be partially addressed by carefully choosing the independent variable, reducing the risk of measurement error, and ensuring that the documentation of the method is sufficiently detailed.\n",
    "- Related concerns include achieving appropriate levels of statistical power and sensitivity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correctly designed experiments advance knowledge in the natural and social sciences and engineering, with design of experiments methodology recognized as a key tool in the successful implementation of a **Quality by Design (QbD)** framework.\n",
    "\n",
    "Other applications include marketing and policy making. The study of the design of experiments is an important topic in **$metascience$**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$Metascience$** (also known as meta-research) is the use of scientific methodology to study science itself. Metascience seeks to increase the quality of scientific research while reducing inefficiency. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[Simple Comparative Experiments](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_1_1_'></a>[Statistical Concepts](#toc0_)\n",
    "\n",
    "<b>$Objectives$</b>\n",
    "\n",
    "1. Basic statistical concepts such as 1) random sampling, 2) probability distributions, 3) sample distributions, and test of hypotheses\n",
    "2. Two-sample t-test, and use it to compare difference in two means\n",
    "3. Confidence intervals to express the difference in means\n",
    "4. Check assumption for the t-test\n",
    "\n",
    "__Remember, we consider experiments to compare two or more conditions (sometimes called treatments).__\n",
    "__These are often called simple comparative experiments. We used the concept of Hypothesis Testing for a simple t-test on the means.__\n",
    "\n",
    "__One way to report the results of a hypothesis test is to state that the null hypothesis was or was not rejected at a specified (ùû™-value or level of significance). This is often called fixed significance level testing.__\n",
    "\n",
    "__The Use of P-Values in Hypothesis Testing is used to avoid many issues associated with testing on statistics.__ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_1_2_'></a>[Example Problem - Illustrates the Statistical Concepts](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An engineer is studying the formulation of a Portland cement mortar. He has added a polymer latex emulsion during mixing to determine if this impacts the curing time and tension bond strength of the mortar. The experimenter prepared 10 samples of the original formulation and 10 samples of the modified formulation. We will refer to the two different formulations as two treatments or as two levels of the factor formulations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"images/Simple Comparative Experiment_1.png\" width=\"540\" height=\"570\" style=\"display: block; margin-left: auto; margin-right: auto; border-radius: 8px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc3_1_2_1_1_'></a>[Graphical Description of Variability](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"images/Simple Comparative Experiment Dot Plot.png\" width=\"640\" height=\"357\" style=\"display: block; margin-left: auto; margin-right: auto; border-radius: 8px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram shows the central tendency, spread, and general shape of the distribution of the data.\n",
    "Recall that a histogram is constructed by dividing the horizontal axis into bins (usually of equal length) and drawing a rectangle over the jth bin with the area of the rectangle proportional to nj , the number of observations that fall in that bin. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc3_1_2_1_2_'></a>[histogram](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"images/histogram_2.png\" width=\"540\" height=\"411\" style=\"display: block; margin-left: auto; margin-right: auto; border-radius: 8px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc3_1_2_1_3_'></a>[ boxplot](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"images/boxplot.png\" width=\"540\" height=\"472\" style=\"display: block; margin-left: auto; margin-right: auto; border-radius: 8px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, in Portland cement mortar formulation experimentation, we can say that $H_0$ : $ùûµ_1$ = $ùûµ_2$ was rejected at the 0.05 level of significance.\n",
    "\n",
    "This statement of conclusions is often inadequate because it gives the decision maker no idea about whether the computed value of the test statistic was just barely in the rejection region or whether it was very far into this region.\n",
    "\n",
    "Furthermore, stating the results this way imposes the predefined level of significance on other users of the information. This approach may be unsatisfactory because some decision makers might be uncomfortable with the risks implied by ùû™ = 0.05 (e.g., 0.01). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_1_2_2_'></a>[General Observations](#toc0_)\n",
    "\n",
    "<span style=\"color:red\"><b> Each of the observations in the Portland cement experiment described above would be called a $\"run\".$ Notice that the individual runs differ, so there is fluctuation, or noise, in the observed bond strengths.</b></span>\n",
    "\n",
    "This noise is usually called \"experimental error\" or simply $error.$ It is a statistical error, meaning that it arises from variation that is uncontrolled and generally unavoidable. \n",
    "\n",
    "#### <a id='toc3_1_2_3_'></a>[Probability Distributions](#toc0_)\n",
    "\n",
    "The probability structure of a random variable, say y, is described by its probability distribution. If y is discrete, we often call the probability distribution of y, say p(y), the probability mass function of y. If y is continuous, the probability distribution of y, say f(y), is often called the probability density function for y. \n",
    "\n",
    "The figs illustrate hypothetical continuous and discrete probability distributions. Notice that in the discrete probability distribution, it is the height of the function p(yj) that represents probability, \n",
    "\n",
    "Whereas in the continuous case it is the area under the curve f(y) associated with a given interval that represents probability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc3_1_2_3_1_'></a>[Probability (continuous)](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"images/probability.png\" width=\"540\" height=\"499\" style=\"display: block; margin-left: auto; margin-right: auto; border-radius: 8px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc3_1_2_3_2_'></a>[Probability (discrete)](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"images/discrete.png\" width=\"540\" height=\"412\" style=\"display: block; margin-left: auto; margin-right: auto; border-radius: 8px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The properties of probability distributions may be summarized quantitatively as follows:\n",
    "\n",
    "**$y$ discrete:**\n",
    "- 0 &le; $p(y_i)$ &le; 1  all values of $y_i$\n",
    "- $p(y = y_i)$ = $p(y_i)$ all values of $y_i$\n",
    "\n",
    "- $\\sum_{all\\: y_i} p(y_i) = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$y$ continuous:**\n",
    "- 0 &le; $f(y)$\n",
    "- P(a &le; y &le; b) = $\\int_{a}^{b} f(y) \\, dy$\n",
    "\n",
    "- $\\int_{-\\infty}^{\\infty} f(y) \\, dy$ = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean, ùûµ, of a probability distribution is a measure of its central tendency or location. Mathematically, we define the mean as \n",
    "\n",
    "- $ùûµ = \\int_{-\\infty}^{\\infty} y f(y)dy$ \\, $y$ continuous\n",
    "- $ùûµ = \\sum_{all\\: y\\:} yp(y)$ \\, $y$ discrete\n",
    "\n",
    "We also have the expected value or the long-run average value $\\: ùûµ = E(y)$\n",
    "\n",
    "- $ùûµ = E(y)= \\int_{-\\infty}^{\\infty} y f(y)dy$ \\, $y$ continuous\n",
    "- $ùûµ = E(y)=\\sum_{all\\:} yp(y)$ \\, $y$ discrete\n",
    "\n",
    "The expected value is found by calculating the weighted value from the data, this represents what can be expected over many trials of the experiment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variability or dispersion of a probability distribution can be measured by the **variance**\n",
    "\n",
    "- $\\sigma^2 = \\int_{-\\infty}^{\\infty} (y-\\mu)^2 f(y)dy$ \\, $y$ continuous\n",
    "\n",
    "- $\\sigma^2 = \\sum_{all\\: y\\:} (y-\\mu)^2 p(y)$ \\, $y$ discrete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Samples**\n",
    "\n",
    "The objective of statistical inference is to draw conclusions about a population using a sample from that population. Most of the methods that we will study assume that **random samples** are used. A **random sample** is a sample that has been selected from the population in such a way that every possible sample has an equal probability of being selected. \n",
    "\n",
    "The **Sample Mean**, **sample variance**\n",
    "\n",
    "\n",
    "$\\bar{y} = \\frac{\\sum_{i=1}^{n}\\: y_i}{n}$\n",
    "\n",
    "$\\:S^2 = \\frac{\\sum_{i=1}^{n}\\: (y_i - \\bar{y})^2}{n-1}$\n",
    "\n",
    "Sometimes $S = \\sqrt{S^2}$, called the **sample standard deviation**, is used as a measure of dispersion. Experimenters often prefer to use the standard deviation to measure dispersion because its units are the same as those for the variable of interest y. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc3_1_2_3_3_'></a>[Degrees of Freedom](#toc0_)\n",
    "\n",
    "The quantity **_n - 1_** in the Estimator Sample Variance is called the number of degrees of freedom of the sum of squares SS.\n",
    "\n",
    "The number of degrees of freedom of a sum of squares is equal to the number of independent elements in that sum of squares.\n",
    "\n",
    "Degrees of Freedom Formula\n",
    "The degrees of freedom formula is straightforward. Calculating the degrees of freedom is often the sample size minus the number of parameters (e.g., mean) you‚Äôre estimating:\n",
    "DF = N ‚Äì P\n",
    "\n",
    "Where:\n",
    "N = sample size\n",
    "P = the number of parameters or relationships\n",
    "\n",
    "**Example**\n",
    "\n",
    "For example, the degrees of freedom formula for a 1-sample t test equals N ‚Äì 1 because you‚Äôre estimating one parameter, the mean. To calculate degrees of freedom for a 2-sample t-test, use N ‚Äì 2 because there are now two parameters to estimate.\n",
    "\n",
    "##### <a id='toc3_1_2_3_4_'></a>[Normal Distributions](#toc0_)\n",
    "\n",
    "One of the most important sampling distributions is the normal distribution. If y is a normal random variable, the probability distribution of y is\n",
    "\n",
    "\n",
    "$f(y) = \\frac{1}{\\sigma\\sqrt{2 \\pi}}\\:e^{-\\frac{1}{2}[\\frac{y-\\mu}{\\sigma}]^2}$\n",
    "\n",
    "where -‚àû < ùõç < ‚àû is the mean of the distribution and ùõî2 > 0 is the variance. The normal distribution.\n",
    "\n",
    "\n",
    "Because sample runs that differ as a result of experimental error often are well described by the normal distribution, the normal plays a central role in the analysis of data from designed experiments.\n",
    "\n",
    "Many important sampling distributions may also be defined in terms of normal random variables. We often use the notation y ~ N(ùúá, ùúé2) to denote that y is distributed normally with mean ùúá and variance $ùúé^2$. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"images/normal.png\" width=\"440\" height=\"489\" style=\"display: block; margin-left: auto; margin-right: auto; border-radius: 8px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, we are able to determine the probability distribution of a particular statistic if we know the probability distribution of the population from which the sample was drawn. The probability distribution of a statistic is called a sampling distribution. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important special case of the normal distribution is the standard normal distribution; that is, ùúá=0 and $ùúé^2$ = 1.\n",
    "\n",
    "We see that if y ~ N(ùúá, ùúé2), the random variable\n",
    "\n",
    "$ùëß_ùëõ=  \\frac{(ùë•‚àíùëõùúá)}{\\sqrt{n\\sigma^2}}$\n",
    "\n",
    "follows the standard normal distribution, denoted z ~ N(0, 1). The operation demonstrated in the equation above is often called standardizing the normal random variable y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc3_1_2_3_5_'></a>[Central Limit Theorem (CLT)](#toc0_)\n",
    "The Central Limit Theorem (CLT) is one of the most important theorems in probability and statistics. It states that, under certain conditions, the sum (or average) of a large number of independent, identically distributed random variables will be approximately normally distributed, regardless of the original distribution of the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"images/Mean Value Theorem.png\" width=\"740\" height=\"232\" style=\"display: block; margin-left: auto; margin-right: auto; border-radius: 8px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc3_1_2_3_6_'></a>[Intuitive Understanding](#toc0_)\n",
    "\n",
    "The Central Limit Theorem explains why the normal distribution is so prevalent in statistics. It tells us that even if we are sampling from a population that is not normally distributed, the distribution of the sample means will tend to be normal as long as the sample size is large enough. This is why the normal distribution appears in many practical scenarios.\n",
    "\n",
    "**Example:**\n",
    "Example: Customer Wait Times\n",
    "\n",
    "Imagine you own a restaurant, and you want to analyze how long customers typically wait to get their food after placing an order.\n",
    "\n",
    "**Step 1:**\n",
    "\n",
    "Population Distribution:\n",
    "You collect data and realize that the wait times are right-skewed (i.e., most customers wait a short time, but some experience much longer wait times). This type of distribution is not normal.\n",
    "Let's assume the average wait time (mean) for all customers is Œº=10 minutes, and the standard deviation is œÉ=5 minutes.\n",
    "\n",
    "**Step 1: Take Random Samples of Wait Times:**\n",
    "\n",
    "Suppose you decide to take samples of 30 customers at a time and record their average wait time.\n",
    "Although the individual customer wait times are skewed, CLT tells us that the distribution of the sample means of 30 customers' wait times will be approximately normal as the sample size n=30 is sufficiently large.\n",
    "\n",
    "**Step 2: Repeat Sampling:**\n",
    "You repeat this process many times: taking random samples of 30 customers, calculating the average wait time for each sample, and plotting these averages.\n",
    "Even though each individual sample may contain customers with very short or very long wait times (skewed data), the distribution of the average wait times across the samples will start to resemble a normal distribution.\n",
    "\n",
    "**Step 3: Distribution of Sample Means:**\n",
    "According to the Central Limit Theorem, the distribution of these sample means will have:\n",
    "\n",
    "Œº=10 minutes (same as the population mean),\n",
    "a standard deviation (standard error) of \n",
    "\n",
    "$ = \\frac{\\sigma}{\\sqrt{n}}\\:\\frac{5}{\\sqrt{30}} = 0.91 \\:minutes$\n",
    "\n",
    "\n",
    "So, while the wait times for individual customers are skewed, the distribution of the average wait times for the 30-customer samples will be approximately normal, centered around 10 minutes, with a standard deviation of about 0.91 minutes.\n",
    "\n",
    "**Step 4: Applying the CLT:**\n",
    "\n",
    "If you take enough samples, the distribution of the sample means will be bell-shaped (normal distribution), which allows you to make predictions using normal distribution techniques.\n",
    "\n",
    "For example, you can now estimate with 95% confidence that the average wait time for any random sample of 30 customers will fall within,\n",
    "\n",
    "10¬±1.96√ó0.91 minutes, or approximately between 8.2 minutes and 11.8 minutes.\n",
    "\n",
    "**Key Takeaways:**\n",
    "\n",
    "The original distribution of customer wait times is right-skewed (non-normal).\n",
    "\n",
    "The sample means of wait times for groups of 30 customers follow an **approximately normal distribution.**\n",
    "\n",
    "This allows you to use normal distribution methods (e.g., confidence intervals, hypothesis testing) on the sample means, even though the underlying wait time data is not normal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc3_1_2_3_7_'></a>[Example Summary](#toc0_)\n",
    "This example demonstrates the Central Limit Theorem by showing that even if the individual data points (customer wait times) do not follow a normal distribution, the distribution of sample means from sufficiently large samples will approximate a normal distribution. This is incredibly useful for drawing conclusions about the population based on sample data, even when the population distribution is unknown or skewed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc3_1_2_3_8_'></a>[Sampling Distributions](#toc0_)\n",
    "\n",
    "\n",
    "One sampling distribution is the **t** distribution with k degrees of freedom, denoted $t_k$\n",
    "\n",
    "- The mean and variance of t are ùúá = 0 and ùúé2 = k/(k - 2) for k > 2, respectively\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$f(t) = \\frac{\\Gamma\\left(\\frac{k+1}{2}\\right)}{\\sqrt{k\\pi} \\, \\Gamma\\left(\\frac{k}{2}\\right)} \\cdot \\frac{1}{\\left(\\frac{t^2}{k} + 1\\right)^{\\frac{k+1}{2}}}, \\quad -\\infty < t < \\infty$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $y_1$, $y_2$, . . . , yn is a random sample from the N(ùúá, $ùúé^2$ ) distribution \n",
    "\n",
    "$t = \\frac{\\bar{y} - \\mu}{S / \\sqrt{n}}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second sampling distribution that we will consider is the F distribution. If $ùúí^2_u$ and $ùúí^2_v$  are two independent chi-square random variables with u and v degrees of freedom, respectively, then the ratio,\n",
    "\n",
    "$F_{u,v} = \\frac{\\chi^2_u \\:/u}{\\chi^2_v \\:/v}$\n",
    "\n",
    "follows the F distribution with **u** numerator degrees of freedom and **v** denominator degrees of freedom. \n",
    "\n",
    "If **_x_** is an **_F_** random variable with **u** numerator and **v** denominator degrees of freedom, then the probability distribution of x is \n",
    "\n",
    "\n",
    "$h(x) = \\frac{\\Gamma\\left(\\frac{u + v}{2}\\right) \\left(\\frac{u}{v}\\right)^{u/2} x^{(u/2) - 1}}{\\Gamma\\left(\\frac{u}{x}\\right) \\Gamma\\left(\\frac{v}{2}\\right) \\left(\\left(\\frac{u}{v}\\right) x + 1\\right)^{(u+v)/2}}, \\quad 0 < x < \\infty$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"images/F Dist2.png\" width=\"540\" height=\"380\" style=\"display: block; margin-left: auto; margin-right: auto; border-radius: 8px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F Sampling Distributions\n",
    "\n",
    "Ex.\n",
    "As an example of a statistic that is distributed as F, suppose we have two independent normal populations with common variance $ùúé^2$. If $y_{11}, y_{12}, . . . , y_{1n1}$  is a random sample of n1 observations from the first population, and if $y_{21}, y_{22}, . . . , y_{2n2}$ is a random sample of $n_2$ observations from the second, then the ratios of the two-sample variances will follow the F distribution, where $S^2_1$ and $S^2_2$ are the two sample variances \n",
    "\n",
    "$\\frac{S_1^2}{S_2^2} \\sim F_{n_1 - 1, n_2 - 1}$\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- $S^2_1$ and $S^2_2$ ‚Äãrepresent the sample variances.\n",
    "- The ‚àº symbol denotes \"is distributed as.\"\n",
    "- $F_{n-1}$ represents the F-distribution with degrees of freedom \n",
    "\n",
    "\n",
    "Inferences About the Differences\n",
    "\n",
    "**Means, Randomized Designs: Hypothesis Testing**\n",
    "\n",
    "\n",
    "\n",
    "$y_{ij} = \\mu_i + \\epsilon_{ij} \n",
    "\\begin{cases} \n",
    "i = 1, 2 \\\\\n",
    "j = 1, 2, \\dots, n_i \n",
    "\\end{cases}$\n",
    "\n",
    "where $y_{ij}$ is the $j^{th}$ observation from factor level i, $ùúá_i$ is the mean of the response at the ith factor level, and $ùúñ_{ij}$ is a normal random variable associated with the $ij^{th}$ observation.\n",
    "\n",
    "It is customary to refer to $ùúñ_{ij}$ as the random error component of the model. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc3_1_2_3_9_'></a>[The sampling situation for the two-sample t-test](#toc0_)\n",
    "\n",
    "A **statistical hypothesis** is a statement either about the parameters of a probability distribution or the parameters of a model.\n",
    "\n",
    "$H_0: \\mu_1 = \\mu_2 \\\\\n",
    "H_1: \\mu_1 \\neq \\mu_2$\n",
    "\n",
    "The statement $H_0$ : ùúá1 = ùúá2 is called the null hypothesis and $H_1$ : ùúá1 ‚â† ùúá2 is called the alternative hypothesis. The alternative hypothesis specified here is called a two-sided alternative hypothesis because it would be true if ùûµ1 < ùûµ2 or if ùûµ1 > ùûµ2. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"images/Screenshot 2024-10-08 at 2.44.49‚ÄØPM.png\" width=\"540\" height=\"320\" style=\"display: block; margin-left: auto; margin-right: auto; border-radius: 8px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_1_3_'></a>[Simple Comparative Experiments: Concepts & Ideas](#toc0_)\n",
    "\n",
    "#### <a id='toc3_1_3_1_'></a>[The Two-Sample t-Test](#toc0_)\n",
    "\n",
    "Suppose that we could assume that the variances of tension bond strengths were identical for both mortar formulations. \n",
    "\n",
    "$t_0 = \\frac{\\bar{y}_1 - \\bar{y}_2}{S_p \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}}$\n",
    "\n",
    "- where $y_1$ and $y_2$ are the sample means, $n_1$ and $n_2$ are the sample sizes, $S^2_p$ is an estimate of the common variance $ùûº^2_1 = ùûº^2_2 = ùûº^2$\n",
    "\n",
    "$S_p^2 = \\frac{(n_1 - 1)S_1^2 + (n_2 - 1)S_2^2}{n_1 + n_2 - 2} \\quad \\text{(Eq. 1)}$\n",
    "\n",
    "- $S_p$ is the pooled variance.\n",
    "\n",
    "$S_p \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}$\n",
    "\n",
    "- often called the standard error of the difference in means \n",
    "\n",
    "\n",
    "- $S^2_1 S^2_2$ are the two individual sample variances\n",
    "\n",
    "\n",
    "\n",
    "- The equation calculates the pooled variance by weighting the group variances according to their degrees of freedom, and it is labeled as \"Eq. 1.\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"images/Screenshot 2024-10-11 at 1.40.29‚ÄØPM_9.png\" width=\"540\" height=\"394\" style=\"display: block; margin-left: auto; margin-right: auto; border-radius: 8px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"images/Screenshot 2024-10-11 at 1.40.43‚ÄØPM_1.png\" width=\"440\" height=\"665\" style=\"display: block; margin-left: auto; margin-right: auto; border-radius: 8px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Screenshot 2024-10-11 at 1.40.56‚ÄØPM_3.png\" width=\"700\" height=\"400\" style=\"display: block; margin-left: auto; margin-right: auto; border-radius: 8px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_1_3_2_'></a>[Recap:](#toc0_)\n",
    "Because $t_0$ = -2.20  less than, $-t_{0.025,18}$ = -2.101, we would reject H0 and conclude that the mean tension bond strengths of the two formulations of Portland cement mortar are different. This is a potentially important engineering finding.\n",
    "\n",
    "The change in mortar formulation had the desired effect of reducing the cure time, but there is evidence that the change also affected the tension bond strength.\n",
    "\n",
    "One can conclude that the modified formulation reduces the bond strength\n",
    "\n",
    "If the reduction in mean bond strength is of practical importance (or has engineering significance in addition to statistical significance) then more development work and further experimentation will likely be required. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
